import requests
from bs4 import BeautifulSoup
import os
import re
import time

# =========================
# CONFIGURACI√ìN
# =========================
BASE_DIR = r"C:\Users\dell\Downloads\pruebas"
LINKS_FILE = "links.txt"
SIN_H1_FILE = "sin_h1_urls.txt"
TIMEOUT = 30
DELAY = 1   # segundos entre requests

os.makedirs(BASE_DIR, exist_ok=True)

# =========================
# UTILIDADES
# =========================
def limpiar_nombre(texto):
    texto = texto.strip()
    # Caracteres inv√°lidos en Windows
    texto = re.sub(r'[\\/:*?"<>|]', '', texto)
    # Espacios m√∫ltiples
    texto = re.sub(r'\s+', ' ', texto)
    # Evitar rutas demasiado largas
    return texto[:180]

# =========================
# CARGAR LINKS
# =========================
with open(LINKS_FILE, "r", encoding="utf-8") as f:
    urls = [u.strip() for u in f if u.strip()]

print(f"üîó URLs detectadas: {len(urls)}")
print(f"üìÅ Carpeta destino: {BASE_DIR}")

# Limpiar archivo de URLs sin H1/TITLE
open(SIN_H1_FILE, "w", encoding="utf-8").close()

# =========================
# PROCESAMIENTO
# =========================
for i, url in enumerate(urls, 1):
    print(f"\n[{i}/{len(urls)}] Procesando:")
    print(url)

    try:
        response = requests.get(
            url,
            timeout=TIMEOUT,
            headers={"User-Agent": "Mozilla/5.0"}
        )
        response.raise_for_status()

        html = response.text
        soup = BeautifulSoup(html, "html.parser")

        h1 = soup.find("h1")
        title = soup.find("title")

        # -------------------------
        # L√ìGICA CORREGIDA
        # -------------------------
        if h1 and h1.get_text(strip=True):
            nombre_base = h1.get_text()
            origen = "H1"
        elif title and title.get_text(strip=True):
            nombre_base = title.get_text()
            origen = "TITLE"
        else:
            print("‚ö†Ô∏è No se encontr√≥ H1 ni TITLE. URL enviada a sin_h1_urls.txt")
            with open(SIN_H1_FILE, "a", encoding="utf-8") as f:
                f.write(url + "\n")
            continue

        nombre_carpeta = limpiar_nombre(nombre_base)

        ruta_carpeta = os.path.join(BASE_DIR, nombre_carpeta)
        os.makedirs(ruta_carpeta, exist_ok=True)

        # Guardar c√≥digo fuente
        ruta_html = os.path.join(ruta_carpeta, "source.html")
        with open(ruta_html, "w", encoding="utf-8") as f:
            f.write(html)

        print(f"‚úÖ Carpeta creada ({origen}): {ruta_carpeta}")

        time.sleep(DELAY)

    except Exception as e:
        print(f"‚ùå Error en {url}: {e}")

print("\nüèÅ Proceso finalizado.")
